{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clone Rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/fastai/fastai.git ../fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "#conda install pillow=6.1\n",
    "from fastai.vision import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from keras import models\n",
    "print('Loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the saved model\n",
    "path = Path('.')\n",
    "learn = load_learner(path)\n",
    "defaults.device = torch.device('cuda')\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Variables and Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font_type = ImageFont.truetype('arial.ttf', 28)\n",
    "leaveupfor = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontscale = 1.5\n",
    "# (B, G, R)\n",
    "color = (0, 0, 255)\n",
    "# select font\n",
    "fontface = cv2.FONT_HERSHEY_COMPLEX\n",
    "thickness = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "_, frame = video.read()\n",
    "im = Image.fromarray(frame, 'RGB')\n",
    "im = im.resize((128,128))\n",
    "t = torch.tensor(np.ascontiguousarray(np.flip(im, 2)).transpose(2,0,1)).float()/255\n",
    "cleanimg = vision.Image(t)\n",
    "\n",
    "pred_class,pred_idx,outputs = learn.predict(cleanimg)\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "per = outputs[0]\n",
    "#per = outputs.numpy()\n",
    "#per = np.squeeze(outputs)\n",
    "per.item()\n",
    "str(pred_class)\n",
    "greatest = outputs.max()\n",
    "greatest.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch camera capture and detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "        _, frame = video.read()\n",
    "        #Convert the captured frame into RGB\n",
    "        #im = Image.fromarray(frame)\n",
    "        im = Image.fromarray(frame, 'RGB')\n",
    "\n",
    "        #Resizing into 128x128 because we trained the model with this image size.\n",
    "        im = im.resize((128,128))\n",
    "        t = torch.tensor(np.ascontiguousarray(np.flip(im, 2)).transpose(2,0,1)).float()/255\n",
    "        cleanimg = vision.Image(t)\n",
    "    #img_array = np.array(im)\n",
    "    ##Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "    ##So changing dimension 128x128x3 into 1x128x128x3 \n",
    "    #img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        #Calling the predict method on model to predict 'me' on the image\n",
    "        pred_class,pred_idx,outputs = learn.predict(cleanimg)\n",
    "        greatest = outputs.max()\n",
    "        if str(pred_class) != 'nodog':\n",
    "            if greatest.item() > .6:\n",
    "            #add text\n",
    "                commandlabel = str(pred_class) + \" \" + str(greatest.item())\n",
    "                #cv2.putText(frame, commandlabel, (25, 40), fontface, fontscale, color, thickness)\n",
    "                #cv2.imshow(\"Capturing\", frame)\n",
    "                #time.sleep(1)\n",
    "                leaveupfor = 60\n",
    "        if leaveupfor > 0:\n",
    "            cv2.putText(frame, commandlabel, (25, 40), fontface, fontscale, color, thickness)\n",
    "        cv2.imshow(\"Capturing\", frame)\n",
    "        leaveupfor = leaveupfor - 1\n",
    "        key=cv2.waitKey(1)\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-release webcam\n",
    "For troubleshooting purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert notebook to script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m jupyter nbconvert --to python detect_dog.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
